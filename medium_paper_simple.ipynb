{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **[Medium Article]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **1. Introduction**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the last decade, there has been a rising interest within the financial services' industry for applications of natural language processing algorithms. One such application is **sentiment analysis for stock price forecasting**. Although the relationship between stock prices and news articles is not a novel subject, increasing compute power, democratization of machine learning algorithms and the advent of Big Data has made it more easily accessible for financial institutions. Examples of newsworthy events with repercussions on stock market prices include:\n",
    "\n",
    "- Corporate scandals: e.g. Boeing 737 Max's crashes, Rio Tinto's accidental destruction of the Australian Aboriginal Juunkan Gorge, etc.\n",
    "- Market regime changes: e.g. 2007-08 Financial/Real Estate Crisis, COVID-19 Pandemic\n",
    "\n",
    "In past economic litterature, stock market prices were assumed to incorporate all news/textual information available (Eugene Fama's market efficiency hypothesis from 1970). Therefore there were theoretically no gains from mining text information for exploiting arbitrage opportunies (e.g. after major news events, buying/selling a stock before the market reacts and adjusts the stock's market price).\n",
    "\n",
    "While it is a reasonable assumption to make, it is also worth considerating a relaxation of Fama's hypothesis: whereas in the long run, stocks fully incorporate all the available information in their prices, in the short term stock prices don't always adjust immediately to incoming information. There might even be news events that eventually foreshadow future stock price movements (e.g. solvency issues, disappointing sales). Ideally this should be revelatory of arbitrage opportunities that can be exploited for financial gain. \n",
    "\n",
    "From Support Vector Machines to Recurrent Neural Networks, there are many options available for asset managers and data scientists for implementing sentiment analysis on company data. We will explore a novel sentiment analysis approach by researchers Zheng Tracy Ke, Dacheng Xiu and Bryan Kelly: **Supervised Sentiment Extraction via Screening and Topic Modelling** (SSESTM): initially screening words likely for removal of neutral sounding words. Then running ordinary least squares (OLS) to learn 2 seperate sets of sentiment vocabularies (or topics): one that augurs positive returns and another that foreshadows negative returns, which can then be used to score newly unseen documents from 0 to 1 (where 1 indicates a high likelihood of future positive returns). From those scored news articles, they are able to generate investment recommendations: buy stocks with positive news scores, sell stocks with negative scores.\n",
    "\n",
    "Where the algorithm distinguishes itself from competition (such as logistic regression, SVMs or neural networks) is that while it outputs a probability score of text positivity (akin to classification algorithms' predicted probabilities), it accepts continuous variables as a valid input (while typical classification models must be provided categorical values). In essence, it is a \"classification\" algorithm that can accept regression inputs. \n",
    "\n",
    "Following Ke et al. (2019), we attempt to port their algorithm on to our own use-case: from 2015 to 2020, **modeling positive or negative-sentiment generated from news or forum discussions over the Boeing Company**. We will focus on:\n",
    "\n",
    "1. Algorithmic scalability compared to alternative implements of SSESTM freely available on GitHub\n",
    "2. How well Ke's algorithm is capable of handling major market regime changes (e.g. transition from the pre-COVID bullish market regime to the post-COVID environment)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **2. SSESTM**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/1_theory/sestm.png\" width=550 height=350>\n",
    "\n",
    "**Figure 1**: Original from [Ke et al., 2019](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3389884)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Let's assume we have a corpus of $n$ news articles and a lexicon of $m$ word tokens. Thus, we can model our corpus of $n$ documents as a bag of words representation: a document-word matrix $D$ of dimension $\\mathbb{R}^{n \\times m}$.\n",
    "\n",
    "From this corpus $D$, the goal of SSESTM is to learn custom sentiment (positive/negative) dictionnaries from one's own use-case dataset, without having to rely on pre-existing rule-based dictionnaries or purchase expensive solutions from third-party data vendors. This requires two components:\n",
    "\n",
    "- Select a set of words $\\hat S$ that are likely to foreshadow rises/decreases in the phenomena we are trying to forecast. SSESTM accomplishes this simply through word counts. E.g. stopwords (e.g. common words such as \"the\", \"a\", \"thus\",  which are unlikely to portend to any meaning)\n",
    "- From this filtered vocabulary list, weight each word by the sentiment it is the likeliest to foreshadow: e.g. \"stimulus\" for positive returns, \"coronavirus\" for negative returns. This is done through a supervised topic model (akin to Labelled LDA) that learns 2 distinct topics: one for words that presage positive returns ($O_{+}$) and one for words that presage negative returns ($O_{-}$).\n",
    "\n",
    "After learning $O_{+}$ and $O_{-}$, we can infer the sentiment (positive or negative) of unseen news articles $\\hat p$ through maximum likelihood estimation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Screening for excluding neutral words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.1.S1**. For each word $1 \\leq j \\leq m,$ let:\n",
    "\n",
    "<br>\n",
    "\n",
    "$$f_{j}=\\frac{\\# \\text { articles including word } j \\text { AND having } \\operatorname{sgn}(y)=1}{\\# \\text { articles including word } j}$$\n",
    "\n",
    "<br>\n",
    "\n",
    "This first step ranks words based on how often they appear in documents during periods of positive returns. Words with high $f_j$ are likely to augur positive returns, whereas low $f_j$ is likely to portend negative returns. Sandwitched in-between are neutral words, such as stopwords for example, unlikely to be indicative of stock rises/decreases.\n",
    "\n",
    "**2.1.S2**. For a proper threshold $\\alpha_{+}>0, \\alpha_{-}>0,$ and $\\kappa>0$ to be determined, construct:\n",
    "\n",
    "<br>\n",
    "\n",
    "$$\n",
    "\\widehat{S}=\\left\\{j: f_{j} \\geq 1 / 2+\\alpha_{+}\\right\\} \\cup\\left\\{j: f_{j} \\leq 1 / 2-\\alpha_{-}\\right\\} \\cap\\left\\{j: k_{j} \\geq \\kappa\\right\\}\n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "where $k_{j}$ is the total count of articles in which word $j$ appears.\n",
    "\n",
    "Next step is excluding neutral words, i.e. vocabulary with middling $f_j$ values are excluded. The authors require the user to tune multiple hyperparameters:\n",
    "\n",
    "- $\\alpha_{+}$, upper bound for excluding neutral words with average $f_j$\n",
    "- $\\alpha_{-}$, lower bound for excluding neutral words with average $f_j$\n",
    "- $\\kappa$, number of count occurences required (excludes infrequent words)\n",
    "\n",
    "Two opposite pitfalls must be avoided: excluding to many words will drastically limit the size of the vocabulary, but the opposite will diminish the potency of SSESTM. If done optimally, this leads to a large dimensionality reduction, which explains how the authors claim that their approach can run on laptop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Learning Positive/Negative Vocabulary Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After filtering out neutral words, the next step is learning positive/negative term vocabularies from our data. One approach would to run a LASSO regression classifier on our corpus $D_{[\\hat S]}$ (minus the neutral words) with words acting as features. We obtain positive/negative weights for a decent number of words and therefore our positive/negative vocabularies. The authors prefer to implement a generative model instead, where the joint distribution between words and returns is fully specified and learned from data.\n",
    "\n",
    "A popular generative model for modelling a distribution of words over documents is topic models and for learning positive/negative dictionnaries, the authors construct what they describe to be a \"2-topic topic model\" that models positive auguring words as its first topic $\\widehat{O}_{+}$ and negative auguring terms as its second topic $\\widehat{O}_{-}$. Their \"2-topic topic model\" differs somewhat from classical topic models as the vast majority of topic models are unsupervised and thus don't require inputting labels. In contrast, the authors' model is a form of supervised topic model which are rarer in topic modeling litterature (e.g. Labelled LDA).\n",
    "\n",
    "In this supervised topic model with 2 topics, each document $\\hat{d}_{i,[S]}$ is modelled with a multinomial distribution:\n",
    "\n",
    "<br>\n",
    "\n",
    "$$ {d}_{i,[S]} \\sim \\text{Multinomial}\\left(s_i, p_i O_{+} + (1 - p_i) O_{-}\\right) $$\n",
    "\n",
    "<br>\n",
    "\n",
    "The expected value of $\\hat{d}_{i,[S]}$ can thus be written as:\n",
    "\n",
    "<br>\n",
    "\n",
    "$$ \\mathbb{E}({d}_{i,[S]}) = p_i O_{+} + (1 - p_i) O_{-} $$\n",
    "\n",
    "<br>\n",
    "\n",
    "We now need to learn $\\hat p_i$ and topics/vocabularies $\\widehat{O}_{+}$ and $\\widehat{O}_{-}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.2.S3**. For learning $\\hat p_i$, the authors rely on rank statistics, which are known to be more robust to outliers. Sort the returns $\\left\\{y_{i}\\right\\}_{i=1}^{n}$ in ascending order. For each $1 \\leq i \\leq n,$ let:\n",
    "\n",
    "<br>\n",
    "\n",
    "$$\n",
    "\\widehat{p}_{i}=\\frac{\\text { rank of } y_{i} \\text { in all returns }}{n}\n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "This phase is extremely important since it will determine whether words are seen as generating positive or negative sentiment. Each article is ranked by its associated return, thus words that are frequently present in the articles with the best returns are much more likely to be seen as positive sounding. Conversely, words present in the articles with the worst performing returns will be seen as foreshadowing negative sentiment. So it is not necessarily the sign of returns (increase or decrease) that dictates word sentiment, but rank of returns.\n",
    "\n",
    "**2.2.S4**. Now we need to estimate our topics of positive words $O_{+}$ and negative words $O_{-}$. We wish to express all corpus documents $D$ as a weighted combination of positive and negative sentiment words:\n",
    "\n",
    "<br>\n",
    "\n",
    "$$ D^{'} = O W^{\\prime} $$\n",
    "\n",
    "<br>\n",
    "\n",
    "According to the authors, $O$ can be approximated with an ordinary least squares (OLS) of $D$ on $W$:\n",
    "\n",
    "<br>\n",
    "$$\n",
    "\\widehat{O}=\\widehat{D} \\widehat{W}^{\\prime}\\left(\\widehat{W} \\widehat{W}^{\\prime}\\right)^{-1}, \\quad \\text { where } \\quad \\widehat{W}=\\left[\\begin{array}{cccc}\n",
    "\\widehat{p}_{1} & \\widehat{p}_{2} & \\cdots & \\widehat{p}_{n} \\\\\n",
    "1-\\widehat{p}_{1} & 1-\\widehat{p}_{2} & \\cdots & 1-\\widehat{p}_{n}\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "<br>\n",
    "\n",
    "Set negative entries of $\\widehat{O}$ to zero and re-normalize each column to have a unit $\\ell^{1}$ -norm. We use the same notation $\\widehat{O}$ for the resulting matrix. We also use $\\widehat{O}_{\\pm}$ to denote the two columns of $\\widehat{O}=\\left[\\widehat{O}_{+}, \\widehat{O}_{-}\\right]$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Infering Sentiment from Unseen News Articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For inferring the sentiment score for newer articles, the authors use maximum likelihood estimation to infer $\\hat p$. As stated in the introduction, SSESTM can take as inputs both categorical targets (stock price increases or decreases) and continuous targets (continuous returns), all the while outputting your typical classification predictive probabilities (here the polarity of a text document).\n",
    "\n",
    "**2.3.S5**. Let $\\widehat{s}$ be the total count of words from $\\widehat{S}$ in the new article. Obtain $\\widehat{p}$ by\n",
    "\n",
    "<br>\n",
    "\n",
    "$$\n",
    "\\widehat{p}=\\arg \\max _{p \\in[0,1]}\\left\\{\\widetilde{s}^{-1} \\sum_{j=1}^{\\hat{s}} d_{j} \\log \\left(p \\widehat{O}_{+, j}+(1-p) \\widehat{O}_{-, j}\\right)+\\lambda \\log (p(1-p))\\right\\}\n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "where $d_{j}, \\widehat{O}_{+, j},$ and $\\widehat{O}_{-, j}$ are the $j$ th entries of the corresponding vectors, and $\\lambda>0$ is a tuning parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **3. Setup**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our approach differs from Ke et al. (2019) in two aspects:\n",
    "\n",
    "- Ke et al. (2019) trained their algorithms on a large Dow Jones news archive (*Dow Jones Newswires Machine Text Feed and Archive*), which spans from January 1989 to December 2012 (with data from February 2004 to July 2017 as their validation set). Our news dataset is more recent as it spans from **January 2015 to November 2020**.\n",
    "- Their dataset size is of size approximatly 13 million news articles (6.5 million for training and 6.7 for validation) and is multi-asset. Our use-case differs considerably as we will be focusing on a **single stock** (here Boeing Company)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will focus on modelling the relationship between returns and text data related to the Boeing Company. Boeing is decent use-case for sentiment analysis with 2 major news events with considerable impact on Boeing Company's market investor appeal: the 737 Max's flight woes and the COVID-19 Pandemic's darkening of the aviation industry. We will use **daily returns** as our variable of interest.\n",
    "\n",
    "<img src=\"images/2_data/boeing_stock_price.png\">\n",
    "\n",
    "**Figure 5**: Boeing Stock Prices at Opening Time (9:00), available on Yahoo Finance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Boeing text inputs, in the past we collected an extremely large corpus of news/blog posts/forum posts from data vendors all stored on a datalake. Through ElasticSearch queries and disambiguation, we were able to obtain respectively 3 million text documents:\n",
    "\n",
    "<img src=\"images/2_data/boeing_article_compo.png\">\n",
    "\n",
    "**Figure 8**: Meta-information on 2.7 million text data available for Boeing (from Jan. 2015 to Nov. 2020)\n",
    "\n",
    "Let's check news count over time for Boeing:\n",
    "\n",
    "<img src=\"images/2_data/boeing_article_count.png\">\n",
    "\n",
    "**Figure 9**: Daily/bi-weekly news count available for Boeing (from Jan. 2015 to Nov. 2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Text Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Stopwords**: words that express no intrinsic meaning and are most commonly used as grammatical expressions (e.g. the, who, where). We can also add a number of commonly used words (e.g. say, months). Our list combines NLTK stopwords with those from spaCy, for a total of 402 stopwords. Note that these words are highly likely to be seen as neutral during our correlation screening for keeping only positive/neutral words thus if we missed a couple of stopwords, SSESTM will take care of exclude them. Additionnally, string expressions representing emails or HTTP links are removed to prevent stopwords such as \"http\" or \"www\" from appearing in our learned vocabularies. Punctuation is also taken care of through regular expressions.\n",
    "\n",
    "- **Lemmatization**: there are many redundant word declinations (e.g. plural versions) that can be reduced to a common lemma. Naturally when dealing with millions of text documents with text lengths ranging from a few words to over 100,000 words, this process can be time consuming. As for the library of choice for lemmatization, we opted for spaCy's lemmatization functions on our large corpus.\n",
    "\n",
    "- **Bag-of-word representations**: offer a crucial advantage over alternative representations (such as embeddings), which is interpretability. While there is a wide range of options for training embeddings (or relying on pretrained embeddings), bag-of-word representations are much easier to understand and most importantly control: if our algorithm fails to perform, we can simply check the inputs for irregularities (assuming we use mostly-interpretable supervised learning models). In practice to represent our text as bag-of-words, we rely on Scikit-Learn (or Dask ML) and its function `CountVectorizer`. It conveniantly outputs the bag-of-words matrix as a sparse matrix for ease in storing and computing.\n",
    "\n",
    "- **Tokenization**: for simplicity, we restrict ourselves to unigrams."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. Model Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We provide a description of how we implemented **SSESTM**:\n",
    "\n",
    "- **Removal of neutral words**: there are two steps for removing neutral words. The first is to create a bag-of-word representation for every token and then filter out words that empirically appear equally during bullish/bearish market regimes. For bag-of-word representation, we utilize Scikit-Learn's CountVectorizer function (which can be substitued with a multithreaded variant provided by Dask ML) which returns a bag-of-word representation under sparse matrix format (which is crucial for improving computational speed and limit RAM usage). For filtering out neutral words, we compute a matrix dot product between the bag-of-word representation and the target vector (positive or negative returns). This allows to compute word frequencies only on documents on days preceding stock price increases/decreases, which will allow us to find and exclude neutral words. This reveals to be extremely memory-efficient and fast, especially when dealing with representations of over 2 million documents;\n",
    "\n",
    "- **Learning sentiment topics/vocabularies**: for this step we need to implement rank statistics then an ordinary least squares (OLS), which can be simply through `numpy` functions;\n",
    "\n",
    "- **Scoring out-of-sample documents**: for maximum likelihood estimation (MLE), we implement `scipy` optimization functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4. Learning Strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naturally, training our algorithm on the entire dataset would prevent us form capturing changes in word polarity over time (e.g. how investors and news outlets soured on Boeing's 737 Max after multiple incidents).\n",
    "\n",
    "In the original paper from Ke et al. (2019), the authors considered Dow Jones' stocks spanning from 2004 to 2017 and updating their model every year (on a rolling window basis), thus a 14 training sets in total. Word polarity can change over time from highs (e.g. new announcements concerning Boeing's new 737 Max, Trump tax cuts) to lows (e.g. 737 Max crashes, COVID-19) so it is important to factor in evolving market regimes. For our results, we will train SSESTM on a **24-week (or approximately 6 month) sliding window**. After training on 1 sample, we **shift the training window by 1 week**, starting from January 5th 2015 and ending in October 2020."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ideal choice for hyperparameters is much trickier decision to be made. Let's start with the issue of excluding neutral words. The authors give users the option to set a lower/upper bound given a 50% threshold of word apperance in text documents published during positive market regimes. E.g. in our Boeing use-case, we could exclude words with apperance values between 48% and 52%. But this assumes a balanced distribution for our prediction variable (returns), which is unlikely to be verified in a real life environment as we addressed beforehand. The following chart illustrates changes in word frequency over time:\n",
    "\n",
    "<img src=\"images/4_results/vocab_dynamics.png\">\n",
    "\n",
    "**Figure 13**: [TODO: Word co-occurence with positive returns]\n",
    "\n",
    "An easy temporary fix would be to dynamically set thresholds for excluding neutral words: during bullish markets, thresholds would be increased from 50% and conversely decreased during bearish markets. For each training set, we will take the median polarity as our threshold (e.g. if \"boeing\" has a polarity of 0.43 and represents the median polarity of our vocabularity then 43% is our threshold).\n",
    "\n",
    "In our use-case, we have retained the following hyperparameters (the $\\lambda$ hyperparameter is out-of-scope since we are focusing on modelling word sentiment):\n",
    "\n",
    "- $\\alpha_{+} = \\alpha_{-} = 0.01$\n",
    "- $\\kappa = 1500$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will be comparing our implementation of SESTM with alternative versions freely available on GitHub, measuring differences in execution time and memory usage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **4. Results**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Algorithmic scalability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our working environment is an Intel Xeon with 8 cores and 64GB of RAM. We ran both our algorithmic implementation of SSESTM and an alternative available on GitHub from [mrepetto94](https://github.com/mrepetto94/sentiment_modelling) on a 50,000 subset of our 2.7 million news articles. Training for our implementation took **23 seconds**, whereas the GitHub alternative took **12 minutes and 34 seconds**.\n",
    "\n",
    "And as a bonus, we ran our implementation of SSESTM on the entirety of the 2.7 million text documents. In this case, training took **19 minutes and 55 seconds**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Word probability distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After learning positive $O_{+}$ and negative $O_{-}$ scores, similarly to Ke et al. (2019) we compute the average sentiment tone: \n",
    "\n",
    "<br>\n",
    "\n",
    "$$T_{d} = O_{+,d} - O_{-,d}$$\n",
    "\n",
    "<br>\n",
    "\n",
    "for each word $d$. We compute the average sentiment tone for our training samples pre-COVID and display through wordclouds both the words with the highest tone (words associated with positive returns) and those with lowest tone (words associated with negative words).\n",
    "\n",
    "In total, we trained SSESTM on 300 **24-week training samples** spanning from January 2020 to October 2020. We plot a few wordclouds of those training samples to illustrate how investor sentiment over Boeing changed over time:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/4_results/wordcloud_0.png\">\n",
    "\n",
    "Overall, the first semester of 2015 was overall a positive environment for Boeing. At the start of the year, news events favoring positive returns include the signing of contracts by NASA over Boeing's reusable spacecraft CST-100 Starliner and SpaceX competitor Crew Dragon.\n",
    "\n",
    "<img src=\"images/4_results/wordcloud_1.png\">\n",
    "\n",
    "Second semester of 2016 saw competition between Lockheed Martin and Boeing over the replacement of the United States Navy's aging fleet of Boeing F-18 Super Hornet hets, with Boeing offering a revamp of its Super Hornets whereas Lockheed Martin was building a stealthier replacement with the F-35 Lightning II. Boeing eventually lost against rivals Lockheed. Following Donald Trump's election in November 2016, the president-elect tweeted a salvo of critical comments over the F-35 Lightning's spiraling costs, which most likely helped boost Boeing's stock price.\n",
    "\n",
    "<img src=\"images/4_results/wordcloud_3.png\">\n",
    "\n",
    "Starting on the 22nd of January 2018, Trump sparked a trade war between the US and China with a salvo of unilateral tarriffs on imported Chinese goods (including solar panels, aluminium, washing machines and steel). The Chinese gouvernment retaliated with tariffs on US goods. Rising geopolitical tensions between the two biggest world superpowers increased the risk of military conflict and the potential for military aviation contracts between Boeing and US allies in the region. Conversely, negative topics include a crash of a Boeing 737-201 in Cuba on May 18th 2018.\n",
    "\n",
    "<img src=\"images/4_results/wordcloud_4.png\">\n",
    "\n",
    "Naturally the major event that damaged Boeing's reputation and investor confidence was the double accidents related to the Boeing 737 Max's faulty MCAS and its subsequent grounding by aviation authories all the around the globe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus to summarize, some subjects that led to **positive returns** (optimistic investor behaviour) include:\n",
    "\n",
    "- Geopolitical tensions in South East Asia (\"china\", \"tariff\") favoring arms sales for Boeing (\"military\", \"buy\", \"contract\") with references to US leaders or state officials (\"trump\", \"matthis\")\n",
    "- Opportunities for space exploration and collaboration with both NASA and the private sector (\"space\", spacex\", \"nasa\"). For example, towards the end of 2014, for resupplying the International Space Station, NASA signed contracts with Boeing (Starliner) and SpaceX (Crew Dragon) for its reusable spacecrafts.\n",
    "\n",
    "Negative subjects that led to **negative returns** (pessimistic investor behaviour):\n",
    "\n",
    "- Boeing aicraft accidents (\"crash\", \"safety\", \"kill\", \"fatal\", \"tragedy\") including the now reputationnally-damaging 737 Max crashes (\"max\", \"mcas\", \"sensor\", \"faa\", \"ethiopia\", \"ethiopian\", \"ababa\", \"indonesia\") which lead to the aircraft's grounding from March 2019 to November 2020 (\"ground\", \"fleet\"). Additional accidents include accidental shooting down of a Boeing commercial flight by the Iranian military after the assasination of Qasem Soleimani in January 2020 (\"iran\") and a Cubana Aviacion crash of a Boeing in 2018 (\"cuba\", \"havana\")\n",
    "- Boeing losing out against rivals Lockheed Martin over replacing the aging F-18A Super Hornet in the US Navy (\"lockheed\", \"fighter\", \"beat\", \"deal\") in 2017 (despite supporting tweets from Donald Trump)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3. SSESTM during the COVID-19 pandemic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We turn our attention to the COVID-19 pandemic era, which saw the stock market suffer considerable losses. Boeing did claw back some of its losses in the aftermath of the initial downturn. If we look at the COVID-19 pandemic, **from the initial downturn to reassurances of stimulus measures from US Congress (the CARES act), while wordclouds paint a more nuanced and complex picture**:\n",
    "\n",
    "- On the positive spectrum, keywords such as \"bailout\", \"bankrupt\", \"taxpayer\", \"bail\" and \"spend\" indicate that investors were confident that stimulus measures (via loans) from US Congress to ailling businesses will helped brighten Boeing's outlook. \n",
    "- On the negative spectrum, lockdown restrictions from COVID-19 grounded air travel to a halt. Those restrictions crippled the commercial airline industry (\"southwest\", \"airline\"), and also hampered Boeing's attempts to resume flights for its reputation-stricken Boeing 737 Max (\"max\") after two deadly accidents (\"ethiopian\", \"crash\", \"faa\", \"debris\").\n",
    "\n",
    "<img src=\"images/4_results/wordcloud_6.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initially, there was optimism from investors that gouvernmental agencies would finally reauthorize commercial flights for its 737 Boeing after the entire fleet was grounded for almost an entire year. This explains why subjects related to the 737 Max were the high point of news/discussions over Boeing. The most negatively perceived events were the Ukraine International Airlines 752 accidentally being shotdown by the Iranian military in January 2020 (\"ukrainian\", \"debris\", \"iran\", \"teheran\", \"missile\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<img src=\"images/4_results/wordcloud_covid_3.png\">\n",
    "\n",
    "But then the COVID-19 pandemic hit and with restrictions on international travel, investor confidence in the airline industry plummetted (\"coronavirus\", \"outbreak\"). Reassurances from US Congress and the Federal Reserve (\"bailout\", \"bankrupt\") and emergency layoffs (\"worker\", \"layoff\", \"cut\") helped alleviate investor pessimism.\n",
    "\n",
    "<img src=\"images/4_results/wordcloud_covid_5.png\">\n",
    "\n",
    "<img src=\"images/4_results/wordcloud_covid_7.png\">\n",
    "\n",
    "<img src=\"images/4_results/wordcloud_covid_8.png\">\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **5. Conclusion**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our series of results, we applied SSESTM on a large internal corpus of text documents over Boeing, identifying news topics that could either foreshadow positive returns (civilian/military contracts, space exploration, governemental bailouts) or negative returns (crashes and grounding of the 737 Max, COVID-19 outbreak). Rather than looking at the sign of returns (positive or negative) for determining word sentiment, SSESTM ranks returns from best to worst performers and assumes that words looked in text documents that were published on days with the best performing returns generate positif sentiment (and vice-versa for worst performers). Therefore, SSESTM is a promising algorithm giving users an visual description of events that are the most likely to explain positive or negative returns.\n",
    "\n",
    "In our tests, a training size of 24 weeks (or approximately 6 months) was found to be of sufficient size, decent enough for detecting market regime changes, such as moving from a pre-COVID to a post-COVID environment (how \"coronavirus\" was initially seen as a negative subject matter before transitioning to more ambiguous state due to Boeing clawing back some of its stock market losses). *Had our training samples been of insufficient size* [TODO: Hard our training samples been unbalanced], then we would be stumble into environments where returns are either entirely positive or negative. In each case, the worst performing returns would still be positive and the best performers would still be negative respectively. If the training size is chosen haphardly, this modelling choice of determining word sentiment based the ranking of stock returns will bias results. Thus, special care needs to be taken into defining the size of training samples. Other hyperparameters that should be taken into consideration are the algorithm's severity in screening neutral words and the horizon of returns. For the latter, we chose daily returns to keep things simple but we could have used different types of returns.\n",
    "\n",
    "Finally, a possible extension of SSESTM would be for words in both positive and negative return topics to be grouped together, forming coherent subtopics which would simply the interpretation of wordclouds (e.g. \"max.crash.ethopian.lion.mcas\" or \"covid.pandemic.bailout.tax.bankcruptcy\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Sensibility to the training window: need to ensure that distribution of returns adequately captures full picture\n",
    "- Ranking des returns\n",
    "- On a retirer de l'étude l'aspect stratégie (prédire polarité text pour faire du stock picking)\n",
    "- Utile: avoir des explications = avoir les news qui expliquent les returns\n",
    "- Hyperparamètres:\n",
    "    - Taille du train\n",
    "    - Filtrage des mots\n",
    "    - Horizon où les returns sont calculés = conditionne la réussite de l'algo\n",
    "- Si le prix ne fait que monter et il y a \"covid\" => \"covid\" => return positif\n",
    "- Ouverture: mots qui appartiennent au même topic, d'où un travail de topic modelling = grouper des mots ensemble = simplifier la lecture des résultats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  4_train_for_rapport.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dask.bag as db\n",
    "import dask.dataframe as dd\n",
    "from nltk.corpus import stopwords\n",
    "from distributed import Client\n",
    "from spacy.lang.en.stop_words import STOP_WORDS as spacy_stopwords\n",
    "from dask_ml.feature_extraction.text import CountVectorizer as DaskMLCountVectorizer\n",
    "from datetime import datetime\n",
    "SEED = 2077\n",
    "N_JOBS = multiprocessing.cpu_count() - 1\n",
    "\n",
    "\n",
    "# Models & Hyperparameters\n",
    "import shap\n",
    "import tomotopy as tp\n",
    "import lightgbm as lgb\n",
    "from sestm import SESTM\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "# Prepare stopwords list\n",
    "nltk_stopwords = list(stopwords.words('english'))\n",
    "spacy_stopwords = list(spacy_stopwords)\n",
    "STOPWORDS = list(set(nltk_stopwords + spacy_stopwords))\n",
    "STOPWORDS += ['january', 'february', 'march', 'april', 'june', 'july', 'august',\n",
    "              'september', 'october', 'november', 'december', 'com', 'http',\n",
    "              'https', 'said', 'like', 'new', 'year', 'years', 'news', 'boeing']\n",
    "\n",
    "\n",
    "\n",
    "def get_vocab_per_regime(train, test):\n",
    "    \"\"\" AAA\n",
    "    \"\"\"\n",
    "    # Run Dask ML\n",
    "    train_corpus = db.from_sequence(train['text'].values, npartitions=10)\n",
    "    test_corpus = db.from_sequence(test['text'].values, npartitions=10)\n",
    "    vectorizer = DaskMLCountVectorizer(token_pattern = r\"\\b[a-zA-Z]{3,}\\b\",\n",
    "                                       stop_words=STOPWORDS,\n",
    "                                       ngram_range=(1,1),\n",
    "                                       max_features=5000)\n",
    "    X_train = vectorizer.fit_transform(train_corpus).compute()\n",
    "    X_test = vectorizer.transform(test_corpus).compute()\n",
    "    \n",
    "    # Get Word Counts and Frequencies\n",
    "    word_counts = np.sum(X_train, axis=0)\n",
    "    word_counts = np.asarray(word_counts).ravel()\n",
    "    words = vectorizer.get_feature_names()\n",
    "    \n",
    "    # Get co-occurences with positive target\n",
    "    y_target = (train['return'].values > 0.0).astype(int)\n",
    "    docs_with_word_and_target = X_train.T.dot(y_target)\n",
    "    docs_with_word = np.array(X_train.sum(axis=0))\n",
    "    freq = docs_with_word_and_target / docs_with_word\n",
    "    freq = np.asarray(freq).ravel()\n",
    "    \n",
    "    # Get Results\n",
    "    freq_df = pd.Series(freq, index=words).to_frame(name='polarity')\n",
    "    freq_df['count'] = word_counts\n",
    "    freq_df = freq_df.reset_index()\n",
    "    freq_df = freq_df.rename(columns={'index': 'word'})\n",
    "    return X_train, X_test, freq_df\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    # python 4_train_for_rapport.py\n",
    "    # '/home/ubuntu/internal_omicron/cppib_data/boeing-nlp-prep-201501-202011.parquet'\n",
    "    # '/home/ubuntu/internal_omicron/cppib_data/BA.csv'\n",
    "    # '2015-01-05'\n",
    "    # '2020-11-06'\n",
    "    # 'LR'\n",
    "    # 0.0\n",
    "    # 0.0\n",
    "    # 0\n",
    "    # 0.5\n",
    "    \n",
    "    args = sys.argv\n",
    "    \n",
    "    if len(args) == 10:\n",
    "        text_data_path, return_data_path = args[1], args[2]\n",
    "        start_date, end_date = args[3], args[4]\n",
    "        model = args[5]\n",
    "        SESTM_ALPHA_PLUS, SESTM_ALPHA_MINUS, SESTM_KAPPA, SESTM_LAMBDA = args[6], args[7], args[8], args[9]\n",
    "        \n",
    "        # Create output folder\n",
    "        if model == 'SESTM':\n",
    "            output_folder = 'trial_{}_{}_{}_{}'.format(SESTM_ALPHA_PLUS, SESTM_ALPHA_MINUS, SESTM_KAPPA, SESTM_LAMBDA)\n",
    "        else:\n",
    "            output_folder = 'trial_02'\n",
    "        \n",
    "        os.makedirs('../results/{}/{}/'.format(model, output_folder), exist_ok=True)\n",
    "        os.makedirs('../results/{}/{}/preds/'.format(model, output_folder), exist_ok=True)\n",
    "        os.makedirs('../results/{}/{}/topics/'.format(model, output_folder), exist_ok=True)\n",
    "        print('Created folder: ../results/{}/{}/'.format(model, output_folder))\n",
    "        \n",
    "        ### 1 -- TARGET DATA\n",
    "        # Load Return Data\n",
    "        print('TARGET DATA\\n')\n",
    "        horizon = 10\n",
    "        target = 'Open'\n",
    "        target_data = pd.read_csv(return_data_path)\n",
    "        target_data = target_data.rename(columns={'Date': 'date'})\n",
    "        target_data['date'] = pd.to_datetime(target_data['date'])\n",
    "        target_data = target_data.sort_values('date')\n",
    "        \n",
    "        # Create target: Forward Cumulative Returns\n",
    "        # (in the next 't' days, what are the cumulative returns? Are they + or -?)\n",
    "        target_data['return'] = target_data[target] \\\n",
    "                                            .pct_change() \\\n",
    "                                            .rolling(horizon) \\\n",
    "                                            .apply(lambda x: np.sum(x)) \\\n",
    "                                            .shift(-horizon - 1) \\\n",
    "                                            .dropna(how=\"all\")\n",
    "        target_data['date'] = target_data['date'].astype(str)\n",
    "        target_dict = dict(zip(target_data['date'], target_data['return']))\n",
    "        \n",
    "        ### 2 -- TEXT DATA\n",
    "        # Open Text Data and Add Return Data\n",
    "        print('TEXT DATA')\n",
    "        text_data = pd.read_parquet(text_data_path)\n",
    "        print('{}\\n'.format(len(text_data)))\n",
    "        text_data['return'] = text_data['date'].map(target_dict)\n",
    "        text_data['date'] = pd.to_datetime(text_data['date'])\n",
    "        text_data = text_data.dropna(subset=['return'])\n",
    "        text_data = text_data.set_index('date')\n",
    "\n",
    "        ### 3 -- MODEL TRAINING & PREDICTIONS\n",
    "        # Prepare Dates\n",
    "        dates_bw_start = pd.date_range(start=start_date, end=end_date, freq='W-MON')\n",
    "        dates_bw_end = pd.date_range(start=start_date, end=end_date, freq='W-FRI')\n",
    "        dates = [(d1, d2) for d1, d2 in zip(dates_bw_start, dates_bw_end)]       \n",
    "        \n",
    "        # Loop over periods to obtain vocabulary sets\n",
    "        print('MODEL')\n",
    "        \n",
    "        for i, _ in enumerate(dates):\n",
    "\n",
    "            # Get Time Period (12 weeks = 3 months). Ideal: 6 months (24 weeks)\n",
    "            train_period = dates[i:i+12]\n",
    "\n",
    "            if (len(train_period) == 12) and (train_period[-1][-1] != dates[-1][-1]):\n",
    "\n",
    "                test_period = dates[i+12]\n",
    "                start = train_period[0][0]\n",
    "                end = train_period[-1][-1]\n",
    "                \n",
    "                # Get Training/Testing Data\n",
    "                temp_train_data = text_data.loc[start:end, :]\n",
    "                temp_test_data = text_data.loc[test_period[0]:test_period[1], :]\n",
    "                \n",
    "                X_train, X_test, temp_vocab = get_vocab_per_regime(temp_train_data, temp_test_data)\n",
    "                \n",
    "                y_train = temp_train_data['return'].values\n",
    "                y_test = temp_test_data['return'].values\n",
    "                    \n",
    "                temp_vocab['train_start'] = start\n",
    "                temp_vocab['train_end'] = end\n",
    "                temp_vocab['test_start'] = test_period[0]\n",
    "                temp_vocab['test_end'] =  test_period[1]\n",
    "                \n",
    "                progress_string = '{} - Train: {} ==> {}\\tTest: {} ==> {}'.format(\n",
    "                    str(datetime.now()).rsplit('.')[0],\n",
    "                    start.date(),\n",
    "                    end.date(),\n",
    "                    test_period[0].date(),\n",
    "                    test_period[1].date()\n",
    "                )\n",
    "                print(progress_string)\n",
    "                \n",
    "                temp_vocab.to_csv('../results/vocab/trial_02/{}_vocab_12W.csv'.format(\n",
    "                    test_period[0].date()\n",
    "                ))\n",
    "                \n",
    "                \n",
    "                # Launch Model\n",
    "                if model == 'SESTM':\n",
    "                    \n",
    "                    temp_threshold = temp_vocab['polarity'].mean()\n",
    "                    \n",
    "                    # Model Training\n",
    "                    if temp_vocab['polarity'].nunique() == 1:\n",
    "                        print('WARNING: UNIQUE VALUE. NO EXCLUSION.')\n",
    "                        sestm_model = SESTM(\n",
    "                            0.0,\n",
    "                            0.0,\n",
    "                            int(SESTM_KAPPA),\n",
    "                            float(SESTM_LAMBDA),\n",
    "                            threshold=temp_threshold,\n",
    "                            vocab=temp_vocab['word'].values,\n",
    "                            stopwords=STOPWORDS\n",
    "                        )\n",
    "                    else:\n",
    "                        sestm_model = SESTM(\n",
    "                            float(SESTM_ALPHA_PLUS),\n",
    "                            float(SESTM_ALPHA_MINUS),\n",
    "                            int(SESTM_KAPPA),\n",
    "                            float(SESTM_LAMBDA),\n",
    "                            threshold=temp_threshold,\n",
    "                            vocab=temp_vocab['word'].values,\n",
    "                            stopwords=STOPWORDS\n",
    "                        )                        \n",
    "                    \n",
    "                    sestm_model.fit(temp_train_data)\n",
    "                    \n",
    "                    # Predictions\n",
    "                    temp_pred_test = sestm_model.predict(temp_test_data)\n",
    "                    \n",
    "                    # Topics\n",
    "                    temp_O_hat = sestm_model._O_hat_df.T\n",
    "                    temp_O_hat['train_start'] = start\n",
    "                    temp_O_hat['train_end'] = end\n",
    "                    temp_O_hat['test_start'] = test_period[0]\n",
    "                    temp_O_hat['test_end'] =  test_period[1]\n",
    "                    \n",
    "                    temp_O_hat.to_csv('../results/{}/{}/topics/{}_topics.csv'.format(\n",
    "                        model, output_folder, test_period[0].date()\n",
    "                    ))\n",
    "                    \n",
    "                    \n",
    "                elif model == 'NB':\n",
    "                    \n",
    "                    # Predictions\n",
    "                    y_train = (y_train > 0.0).astype(int)\n",
    "                    nb_model = ComplementNB()\n",
    "                    nb_model = nb_model.fit(X=X_train, y=y_train)\n",
    "                    temp_pred_test = nb_model.predict_proba(X_test)[:,1]\n",
    "                    # print(roc_auc_score((y_test > 0.0).astype(int), temp_pred_test))\n",
    "                \n",
    "                elif model == 'LR':\n",
    "                    \n",
    "                    # Predictions\n",
    "                    y_train = (y_train > 0.0).astype(int)\n",
    "                    lr_model = LogisticRegression(C=100, class_weight='balanced',\n",
    "                                                  solver='lbfgs', random_state=SEED)\n",
    "                    lr_model = lr_model.fit(X=X_train, y=y_train)\n",
    "                    temp_pred_test = lr_model.predict_proba(X_test)[:,1]              \n",
    "                    \n",
    "                    # Explainer\n",
    "                    # explainer = shap.Explainer(lr_model, X_train)\n",
    "                    # shap_values = explainer.shap_values(X_test).mean(axis=0)\n",
    "                    # shap_values = pd.Series(shap_values, index=temp_vocab['word'].values)\n",
    "                    \n",
    "                    # shap_values.to_csv('../results/{}/{}/topics/{}_topics.csv'.format(\n",
    "                    #     model, output_folder, test_period[0].date()\n",
    "                    # ))\n",
    "                    \n",
    "                elif model == 'LGBM':\n",
    "                    \n",
    "                    lgb_params = {\n",
    "                        'objective': 'binary',\n",
    "                        'boosting': 'gbdt',\n",
    "                        'num_iterations': 100,\n",
    "                        'num_threads': N_JOBS,\n",
    "                        'seed': SEED,\n",
    "                        'max_depth': 6,\n",
    "                        'lambda_l1': 0.001,\n",
    "                        'lambda_l2': 0.001,\n",
    "                        'num_leaves': 100,\n",
    "                        'verbosity': 0\n",
    "                    }\n",
    "                    \n",
    "                    # Predictions\n",
    "                    lgb_train = lgb.Dataset(X_train.astype(np.float32), label=y_train) \n",
    "                    # lgb_test = lgb.Dataset(X_test.astype(np.float32), label=y_test)\n",
    "                    lgb_model = lgb.train(lgb_params, lgb_train, verbose_eval=50)\n",
    "                    temp_pred_test = lgb_model.predict(X_test.astype(np.float32))\n",
    "                \n",
    "                elif model == 'LLDA':\n",
    "                    \n",
    "                    # Prepare Data\n",
    "                    frequent_words = temp_vocab['word'].values.tolist()\n",
    "                    # print(len(frequent_words))\n",
    "                    corpus_train = tp.utils.Corpus(stopwords=STOPWORDS)\n",
    "                    temp_train_data['return'] = (temp_train_data['return'] > 0.0).astype(int)\n",
    "                    temp_train_data = temp_train_data.sort_values('return')\n",
    "                    \n",
    "                    for doc in temp_train_data.itertuples():\n",
    "                        corpus_train.add_doc(words=doc[1].split(' '), labels=[str(doc[2])])\n",
    "                    \n",
    "                    # Train LLDA\n",
    "                    llda_model = tp.LLDAModel(corpus=corpus_train, seed=SEED)\n",
    "                    llda_model.train(100)\n",
    "                    \n",
    "                    # Predictions\n",
    "                    test_corpus = [\n",
    "                        llda_model.make_doc(doc.split(' ')) for doc in temp_test_data['text']\n",
    "                    ]\n",
    "                    y_pred, _ = llda_model.infer(test_corpus, iter=100, workers=N_JOBS)\n",
    "\n",
    "                    if temp_train_data['return'].mean() == 1.0:\n",
    "                        y_pred_df = pd.DataFrame(y_pred, columns=['POS'])\n",
    "                        y_pred_df['NEG'] = 1.0 - y_pred_df['POS']\n",
    "                        \n",
    "                    elif temp_train_data['return'].mean() == 0.0:\n",
    "                        y_pred_df = pd.DataFrame(y_pred, columns=['NEG'])\n",
    "                        y_pred_df['POS'] = 1.0 - y_pred_df['NEG']\n",
    "                        \n",
    "                    else:\n",
    "                        y_pred_df = pd.DataFrame(y_pred, columns=['NEG', 'POS'])\n",
    "                    \n",
    "                    temp_pred_test = y_pred_df['POS'].values\n",
    "                    \n",
    "                    # Topics\n",
    "                    topic_word_mat = np.stack([llda_model.get_topic_word_dist(k) for k in range(llda_model.k)])\n",
    "                    vocab = np.array(llda_model.used_vocabs)\n",
    "                    \n",
    "                    if temp_train_data['return'].mean() == 1.0:\n",
    "                        print('UNIQUE LABEL: 1.0')\n",
    "                        llda_topics = pd.DataFrame(topic_word_mat.T, columns=['pos'], index=vocab)\n",
    "                        \n",
    "                    elif temp_train_data['return'].mean() == 0.0:\n",
    "                        print('UNIQUE LABEL: 0.0')\n",
    "                        llda_topics = pd.DataFrame(topic_word_mat.T, columns=['neg'], index=vocab)\n",
    "                        \n",
    "                    else:\n",
    "                        llda_topics = pd.DataFrame(topic_word_mat.T, columns=['neg', 'pos'], index=vocab)\n",
    "                    \n",
    "                    llda_topics['train_start'] = start\n",
    "                    llda_topics['train_end'] = end\n",
    "                    llda_topics['test_start'] = test_period[0]\n",
    "                    llda_topics['test_end'] =  test_period[1]\n",
    "                    \n",
    "                    llda_topics.to_csv('../results/{}/{}/topics/{}_topics.csv'.format(\n",
    "                        model, output_folder, test_period[0].date()\n",
    "                    ))\n",
    "                    \n",
    "                    \n",
    "                else:\n",
    "                    raise('Erroneous argument for model provided. Must be SESTM, LR or LLDA.')\n",
    "                \n",
    "                # Save Predictions\n",
    "                temp_pred_test = pd.DataFrame({\n",
    "                    'pred': temp_pred_test, 'dates': temp_test_data.index.get_level_values(0),\n",
    "                    'true': temp_test_data['return'].values\n",
    "                })\n",
    "                \n",
    "                temp_pred_test.to_csv('../results/{}/{}/preds/{}_preds.csv'.format(\n",
    "                    model, output_folder, test_period[0].date()\n",
    "                ))\n",
    "                temp_pred_test\n",
    "            else:\n",
    "                print('Error with dates.')\n",
    "                break\n",
    "        \n",
    "        # print('')\n",
    "        # print('ROC AUC Test\\t:', roc_auc_score(pred_test['true'], pred_test['pred']), '\\n')\n",
    "        \n",
    "    else:\n",
    "        print('Irregular number of arguments. Requires 7 not {}.'.format(len(args)-1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sestm.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize_scalar\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import re\n",
    "\n",
    "class SESTM:\n",
    "    '''\n",
    "    Implements a new text-mining methodology that extracts sentiment information from news\n",
    "    articles to predict asset returns.\n",
    "    The algorithm is detailed in: https://bfi.uchicago.edu/wp-content/uploads/BFI_WP_201969.pdf\n",
    "    '''\n",
    "\n",
    "    def __init__(self, alpha_plus, alpha_minus, kappa, lambda_reg, stopwords,\n",
    "                 threshold=0.5, vocab=None):\n",
    "        self.df = None\n",
    "        self.alpha_plus = alpha_plus\n",
    "        self.alpha_minus = alpha_minus\n",
    "        self.kappa = kappa\n",
    "        self.lambda_reg = lambda_reg\n",
    "        self._O_hat_df = None\n",
    "        self.word_count = None\n",
    "        self._cv = None\n",
    "        self._fj_vector = None\n",
    "        self._word_count_pred = None\n",
    "        self._opt_res = None\n",
    "        self.stopwords = stopwords\n",
    "        self.vocab = vocab\n",
    "        self.threshold = threshold\n",
    "        \n",
    "\n",
    "    def _compute_word_count(self, df):\n",
    "        '''computes word count of the dataframe df.'''\n",
    "        self.df = df\n",
    "        self.cv = CountVectorizer(\n",
    "            stop_words=self.stopwords,\n",
    "            token_pattern=r\"\\b[a-zA-Z]{3,}\\b\",\n",
    "            ngram_range=(1, 1),\n",
    "            vocabulary=self.vocab\n",
    "        )\n",
    "        self.cv.fit(self.df['text'].values)\n",
    "        self.word_count = self.cv.transform(self.df['text'].values)\n",
    "\n",
    "\n",
    "    def print_word_count_df(self):\n",
    "        return pd.DataFrame.sparse.from_spmatrix(self.word_count , columns=self.cv.get_feature_names())\n",
    "\n",
    "\n",
    "    def _compute_fj(self):\n",
    "        ''' computes the fj vector that gives the frequence at which the word appears with a positive return'''\n",
    "        num = (self.word_count != 0).astype(int).T.dot((self.df['return'].values > 0))\n",
    "        den = np.array((self.word_count != 0).astype(int).sum(axis=0))\n",
    "        return num / den\n",
    "\n",
    "    def _get_non_neutral_words(self):\n",
    "        ''' remove neutral words from the dictionary'''\n",
    "        mask_pos = self._fj_vector >= (self.threshold + self.alpha_plus)\n",
    "        mask_neg = self._fj_vector < (self.threshold - self.alpha_minus)\n",
    "        mask_freq = np.array(self.word_count.sum(axis=0))[0] >= self.kappa\n",
    "        mask_filtered_tokens = np.logical_and(np.logical_or(mask_pos, mask_neg), mask_freq)\n",
    "        return mask_filtered_tokens.ravel()\n",
    "\n",
    "    def _compute_p_hat(self):\n",
    "        ''' computes p_hat that is a return's proxy (more stable)'''\n",
    "        return self.df['return'].rank().values / len(self.df['return'])\n",
    "\n",
    "\n",
    "    def _minus_log_likelihood(self, p ):\n",
    "        ''' computes the log likelihood of the multinomial law '''\n",
    "\n",
    "        subset_of_training = self._word_count_pred.columns[(self._word_count_pred != 0).values[0]]\n",
    "        word_count = self._word_count_pred[subset_of_training].T.values\n",
    "        log_term = np.log(p * self._O_hat_df[subset_of_training].loc['pos', :].values.reshape(-1, 1) + \\\n",
    "                          (1 - p) * self._O_hat_df[subset_of_training].loc['neg', :].values.reshape(-1, 1))\n",
    "        log_term[log_term == -np.inf] = 0\n",
    "        log_term[log_term == np.inf] = 0\n",
    "\n",
    "        reg_term = self.lambda_reg * np.log(p * (1 - p))\n",
    "        term = word_count * log_term + reg_term\n",
    "        return - np.sum(term)\n",
    "\n",
    "    def fit(self, df):\n",
    "        '''train the model'''\n",
    "        self._compute_word_count(df)\n",
    "        self._fj_vector = self._compute_fj()\n",
    "        mask_filtered_tokens = self._get_non_neutral_words()\n",
    "        S_hat = self.word_count[:,mask_filtered_tokens]\n",
    "        p_hat = self._compute_p_hat()\n",
    "        W_hat = np.array([p_hat, 1 - p_hat])\n",
    "        #fillna 0 because some filtered words let some documents empty, which leads to NaN\n",
    "        D_hat = S_hat.T.multiply(1/np.array(S_hat.sum(axis=1)).reshape(1,-1)[0])\n",
    "        O_hat = np.dot(D_hat.dot(W_hat.T), np.linalg.inv(np.dot(W_hat, W_hat.T)))\n",
    "        O_hat_plus = O_hat.clip(min=0)[:, 0] / O_hat.clip(min=0)[:, 0].sum()\n",
    "        O_hat_minus = O_hat.clip(min=0)[:, 1] / O_hat.clip(min=0)[:, 1].sum()\n",
    "        O_hat = np.array([O_hat_plus, O_hat_minus])\n",
    "        self._O_hat_df = self._format_O_hat_df(O_hat, mask_filtered_tokens)\n",
    "\n",
    "    def _format_O_hat_df(self, O_hat, mask_filtered_tokens):\n",
    "        columns = np.array(self.cv.get_feature_names())[mask_filtered_tokens]\n",
    "        return pd.DataFrame(O_hat,\n",
    "                            columns= columns,\n",
    "                            index=['pos', 'neg'])\n",
    "\n",
    "\n",
    "\n",
    "    def predict(self, df):\n",
    "        '''predict the positivity of a new document'''\n",
    "        word_count_pred = pd.DataFrame.sparse.from_spmatrix(\n",
    "                self.cv.transform(df['text']), columns=self.cv.get_feature_names()\n",
    "                )\n",
    "        \n",
    "        # Filter out neutral-sentiment words from test set\n",
    "        mask_filtered_tokens = self._get_non_neutral_words()\n",
    "        non_neutral_words = np.array(self.cv.get_feature_names())[mask_filtered_tokens]\n",
    "        word_count_pred = word_count_pred[non_neutral_words]\n",
    "        \n",
    "        preds = []\n",
    "        for _, doc in word_count_pred.iterrows():\n",
    "            self._word_count_pred = doc.to_frame().T\n",
    "            self._opt_res = minimize_scalar(self._minus_log_likelihood, bounds=(0, 1), method='bounded')\n",
    "            p_star = self._opt_res.x\n",
    "            preds.append(p_star)\n",
    "        \n",
    "        return np.array(preds)\n",
    "\n",
    "    def _get_topics(self, n):\n",
    "        '''returns positive and negative topics'''\n",
    "        pos_freq_words = (self._O_hat_df.loc['pos'].sort_values(ascending=False)[:n] * 100000).astype(int).to_dict()\n",
    "        neg_freq_words = (self._O_hat_df.loc['neg'].sort_values(ascending=False)[:n] * 100000).astype(int).to_dict()\n",
    "        return pos_freq_words, neg_freq_words\n",
    "\n",
    "    def makeImage(self, text, show=False):\n",
    "        '''helper method to plot a wordcloud in a circular fashion'''\n",
    "        x, y = np.ogrid[:1000, :1000]\n",
    "        mask = (x - 500) ** 2 + (y - 500) ** 2 > 500 ** 2\n",
    "        mask = 255 * mask.astype(int)\n",
    "        wc = WordCloud(background_color=\"white\", repeat=True, mask=mask)\n",
    "        # generate word cloud\n",
    "        wc.generate_from_frequencies(text)\n",
    "        # show\n",
    "        plt.imshow(wc, interpolation=\"bilinear\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()\n",
    "\n",
    "    def _plot_pos_topics(self, n):\n",
    "        '''plot wordcloud of positive topics'''\n",
    "\n",
    "        pos_freq_words = self._get_topics(n)[0]\n",
    "        self.makeImage(pos_freq_words, show=False)\n",
    "\n",
    "    def _plot_neg_topics(self, n):\n",
    "        '''plot wordcloud of negative topics'''\n",
    "\n",
    "        neg_freq_words = self._get_topics(n)[1]\n",
    "        self.makeImage(neg_freq_words, show=False)\n",
    "\n",
    "    def plot_topics(self, n):\n",
    "        '''plot wordcloud of positive and negative topics'''\n",
    "        print('Preparing topics plots ... ')\n",
    "        self._plot_pos_topics(n)\n",
    "        self._plot_neg_topics(n)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1_preproc_json_to_dataframe.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import vaex\n",
    "\n",
    "\n",
    "def read_huge_json_to_dataframe(path):\n",
    "    \"\"\" Utility to read NLP +10GB JSON files into DataFrames\n",
    "    \"\"\"\n",
    "    # pandas.read_json crashes RAM\n",
    "    with open(path) as f:\n",
    "        data = pd.DataFrame(json.loads(line) for line in f)\n",
    "    \n",
    "    # Meta info (site, site_type, country) is a column\n",
    "    # of dictionnaries\n",
    "    meta = pd.DataFrame(list(data['thread']))\n",
    "    data = pd.concat([data, meta], axis=1, ignore_index=False)\n",
    "    del data['thread']\n",
    "    \n",
    "    # Some titles are under list form\n",
    "    data['title'] = data['title'].apply(lambda x: '' if isinstance(x, list) else x)\n",
    "    \n",
    "    # Country has mixed types (str, float, list)\n",
    "    data['country'] = data['country'].apply(lambda x: '' if isinstance(x, list) else x)\n",
    "    data['country'] = data['country'].fillna('')\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    # Get path for raw data\n",
    "    # Examples:\n",
    "    # raw_path = '/home/ubuntu/data/boeing.json'\n",
    "    # new_path = '/home/ubuntu/internal_omicron/cppib_data/boeing-nlp-data-201501-202011.hdf5'\n",
    "    args = sys.argv\n",
    "    \n",
    "    if len(args) == 3:\n",
    "        raw_path, new_path = args[1], args[2]\n",
    "\n",
    "        # Load JSON Dataset\n",
    "        data = read_huge_json_to_dataframe(raw_path)\n",
    "\n",
    "        # Convert Pandas DataFrame to Vaex DataFrame\n",
    "        vaex_df = vaex.from_pandas(data, copy_index=False)\n",
    "\n",
    "        # Combine Title and Text Body (this operation in Pandas leads to\n",
    "        # kernel shutdown)\n",
    "        vaex_df['text'] = vaex_df['title'] + ' ' + vaex_df['text']\n",
    "\n",
    "        # Lowercase\n",
    "        vaex_df['text'] = vaex_df['text'].str.lower()\n",
    "        \n",
    "        # Save Vaex Format to HDF5 Format\n",
    "        vaex_df.export_hdf5(new_path)\n",
    "        print('Export completed.')\n",
    "        \n",
    "    else:\n",
    "        print('Irregular number of arguments. Requires 2 not {}.'.format(len(args)-1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2_preproc_raw_to_clean.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import vaex\n",
    "import re\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "from spacy.lemmatizer import Lemmatizer\n",
    "from spacy.lang.en.stop_words import STOP_WORDS as spacy_stopwords\n",
    "from dask_ml.feature_extraction.text import CountVectorizer as DaskMLCountVectorizer\n",
    "\n",
    "\n",
    "# Prepare stopwords list\n",
    "nltk_stopwords = list(stopwords.words('english'))\n",
    "spacy_stopwords = list(spacy_stopwords)\n",
    "STOPWORDS = list(set(nltk_stopwords + spacy_stopwords))\n",
    "STOPWORDS += ['january', 'february', 'march', 'april', 'june', 'july', 'august',\n",
    "              'september', 'october', 'november', 'december', 'com', 'http',\n",
    "              'https', 'said', 'like', 'new', 'year', 'years', 'news']\n",
    "\n",
    "# Speeds up massively Spacy Lemmatization\n",
    "nlp = spacy.load('en_core_web_lg', disable=['tagger', 'parser', 'ner'])\n",
    "nlp.add_pipe(nlp.create_pipe('sentencizer'))\n",
    "\n",
    "\n",
    "def lemmatize_pipe(doc):\n",
    "    \"\"\" AAA\n",
    "    \"\"\"\n",
    "    lemma_list = [str(tok.lemma_).lower() for tok in doc\n",
    "                  if ((tok.is_alpha) and\n",
    "                      (tok.lemma_ not in STOPWORDS)) and\n",
    "                      (len(tok.lemma_) >= 3)]\n",
    "    lemma = ' '.join(lemma_list)\n",
    "    return lemma\n",
    "\n",
    "def preprocess_pipe(texts):\n",
    "    \"\"\" AAA\n",
    "    \"\"\"\n",
    "    preproc_pipe = []\n",
    "    for doc in nlp.pipe(texts, batch_size=200):\n",
    "        preproc_pipe.append(lemmatize_pipe(doc))\n",
    "    return preproc_pipe\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    # Get paths for data\n",
    "    # Examples:\n",
    "    # new_path = '/home/ubuntu/internal_omicron/cppib_data/boeing-nlp-data-201501-202011.hdf5'\n",
    "    # clean_path = '/home/ubuntu/internal_omicron/cppib_data/boeing-nlp-prep-201501-202011.parquet'\n",
    "    args = sys.argv\n",
    "    \n",
    "    if len(args) == 3:\n",
    "        new_path, clean_path = args[1], args[2]\n",
    "\n",
    "        # Open Data\n",
    "        data = vaex.open(new_path) #.head(100000)\n",
    "        data = data[data['text'].str.len() <= 300000]\n",
    "        print('Loading {} documents'.format(len(data)))\n",
    "        \n",
    "        # Dates\n",
    "        data['crawled'] = data['crawled'].astype('datetime64[ns]')\n",
    "        data['date'] = data['crawled'].astype('datetime64[D]')\n",
    "        data['date'] = data['date'].astype(str)\n",
    "\n",
    "        # Text Preprocessing with Regular Expressions\n",
    "        punct = \"\"\"-!\"'#&$%\\()*+,.:;<=>?@[\\\\]^_`{|}~–’\"\"\"\n",
    "        punc_pattern = '{}'.format('|'.join(['\\\\'+char for char in punct]))\n",
    "        full_regex_pattern = r'(\\S*@\\S*\\s?|http\\S+|https\\S+|\\s+|{})'.format(punc_pattern)\n",
    "        data['text'] = data['text'].str.replace(full_regex_pattern, ' ', regex=True)\n",
    "\n",
    "        # Lemmatization\n",
    "        print('Regular expressions')\n",
    "        data_pandas = data.to_pandas_df(column_names=['date', 'text'])\n",
    "        \n",
    "        print('Lemmatization')\n",
    "        data_pandas['text'] = preprocess_pipe(data_pandas['text'])\n",
    "        \n",
    "        # Export to Parquet\n",
    "        data_pandas.to_parquet(clean_path)\n",
    "        print('Exported to parquet')\n",
    "        \n",
    "    else:\n",
    "        print('Irregular number of arguments. Requires 2 not {}.'.format(len(args)-1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
